# Using Visual Speech Information in MaskingMethods for Audio Speaker Separation

## Abstract

本文研究了视觉语音信息在基于音频mask的说话人分离中是否可以有效地提高目标语音的质量和清晰度。首先开发了两种仅视觉生成音频mask以实现说话人分离的方法。这些方法使用深层神经网络将视觉语音特征映射到音频特征空间，从中估计出视觉驱动的二进制mask和视觉驱动的比率掩码，然后再应用到语音混合中。其次，音频比率屏蔽方法形成了用于说话人分离的基线方法，该基线方法被扩展为利用视觉语音信息来形成音视频比率mask。语音质量和可理解性测试是在说话人分离的纯视觉，纯音频和音视频mask方法上进行的，混音级别为−10至10 dB。当应用纯视觉和纯音频mask时，这些揭示了目标语音的实质性改进，但是当组合音频和视觉信息以创建音视频mask时，性能最高。

**Figure 1**. 对唇部轮廓进行平移，缩放和旋转归一化的Procrustes分析。左图显示了归一化之前的一组40个外部嘴唇轮廓的示例，右图显示了归一化的效果。

**Table 1**. 针对说话者S2，S4，S6和S7使用GMM和DNN方法的滤波器估计误差的均方根
和参考滤波器组的均方根。

**Figure 2**. 对于变化的$\lambda$的DNN和GMM滤波器组估计的二值masking HIT-FA速率

**Table 2**. HIT，FA和HIT-FABINARYMASKESTIMATIONFROMDNNANDGMM过滤器库的估计和直接估计（DNN_MASK）正式男性（MM），女性-女性（FF）和混合性别（MG）的混合

## 1. Introduction

该工作通过研究如何利用视觉语音信息来改善使用mask的方法从混合说话人中提取目标说话人的方法，从而解决了单声道音频说话人分离的问题。对于这项工作，我们采用视觉语音信息来指代从说话人的视觉语音发音器中提取的信息，这些信息主要是指从嘴巴或面部视频中提取的特征。人类非常擅长从干扰说话者的混合物中提取目标说话者。两只耳朵是有益的，并且在某种程度上已被复制为使用多个麦克风的说话人分离系统[1]。此外，人类还能够利用从目标说话人获取的视觉语音信息来改善分离。对于说话人分离的masking方法，对视觉模态的研究还很少，因此这项工作的目的是探索如何利用视觉语音信息。特别地，在扩展到说话者分离的组合视听方法之前，首先考虑说话者分离的仅视觉方法。
